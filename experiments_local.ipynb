{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.vt_resnet20 import VTResNet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "L = 8\n",
    "C = 7\n",
    "H = 32\n",
    "W = 32\n",
    "D = 10\n",
    "\n",
    "x = torch.randn((N, 3, H, W))\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTResNet20(\n",
      "  (resnet20): ResNet(\n",
      "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut): Sequential()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (vt_layers): ModuleList(\n",
      "    (0): VisualTransformer(\n",
      "      (tokenizer): FilterTokenizer(\n",
      "        (linear1): Linear(in_features=64, out_features=8, bias=True)\n",
      "        (linear2): Linear(in_features=64, out_features=512, bias=True)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "              (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.5, inplace=False)\n",
      "              (dropout2): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "              (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.5, inplace=False)\n",
      "              (dropout2): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (decoder): TransformerDecoder(\n",
      "          (layers): ModuleList()\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (projector): Projector(\n",
      "        (linear1): Linear(in_features=64, out_features=512, bias=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (linear3): Linear(in_features=512, out_features=64, bias=True)\n",
      "        (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): VisualTransformer(\n",
      "      (tokenizer): RecurrentTokenizer(\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (linear2): Linear(in_features=64, out_features=512, bias=True)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "              (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.5, inplace=False)\n",
      "              (dropout2): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "            (1): TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): _LinearWithBias(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (dropout): Dropout(p=0.5, inplace=False)\n",
      "              (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.5, inplace=False)\n",
      "              (dropout2): Dropout(p=0.5, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (decoder): TransformerDecoder(\n",
      "          (layers): ModuleList()\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (projector): Projector(\n",
      "        (linear1): Linear(in_features=64, out_features=512, bias=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=False)\n",
      "        (linear3): Linear(in_features=512, out_features=64, bias=True)\n",
      "        (norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vtresnet = VTResNet20(\n",
    "    vt_num_layers=2,\n",
    "    tokens=8,\n",
    "    token_channels=512,\n",
    "    input_dim=32,\n",
    "    vt_channels=64,\n",
    "    transformer_enc_layers=2,\n",
    "    transformer_heads=8,\n",
    "    transformer_fc_dim=512,\n",
    "    transformer_dropout=0.5,\n",
    "    image_channels=3,\n",
    "    num_classes=10,\n",
    "    resnet_pretrained=True,\n",
    "    freeze_resnet=True\n",
    ")\n",
    "print(vtresnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "out = vtresnet(x)\n",
    "print(out.shape)\n",
    "#torch.Size([5, 4, 128])\n",
    "#5 128 2 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.custom_layers import TransposeLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0717, -0.8969, -0.4684, -0.3801],\n",
      "        [ 0.7058,  0.3099,  1.3684, -0.0711],\n",
      "        [ 0.1943,  0.0639, -0.2536, -0.1629]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((3,4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = TransposeLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0717,  0.7058,  0.1943],\n",
      "        [-0.8969,  0.3099,  0.0639],\n",
      "        [-0.4684,  1.3684, -0.2536],\n",
      "        [-0.3801, -0.0711, -0.1629]])\n"
     ]
    }
   ],
   "source": [
    "out = d(x, 0, 1)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
