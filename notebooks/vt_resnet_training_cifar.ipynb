{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "from models.vt_resnet20 import VTResNet20\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from typing import Any\n",
    "from torchsummary import summary\n",
    "\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def store_params(content, name):\n",
    "    f = open(f'params/{name}.pkl','wb')\n",
    "    pickle.dump(content, f)\n",
    "    f.close()\n",
    "\n",
    "def load_params(name):\n",
    "    fl = open(f'params/{name}.pkl', \"rb\")\n",
    "    loaded = pickle.load(fl)\n",
    "    return loaded\n",
    "\n",
    "def store_model(model, name):\n",
    "    torch.save(model.state_dict(), f'./trained_models/{name}.pth')\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'vt_resnet'\n",
    "cores = 12\n",
    "random_seed(8)\n",
    "input_dim = 32\n",
    "batch_size = 128\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((input_dim, input_dim)),\n",
    "    #transforms.RandomResizedCrop(input_dim),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((input_dim, input_dim)),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='/datasets/cifar', train = True, transform = train_transform, download = False)\n",
    "valid_dataset = datasets.CIFAR10(root='/datasets/cifar', train = False, transform = valid_transform, download = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valid_num = len(valid_dataset)\n",
    "total_train_num = len(train_dataset)\n",
    "valid_num = int(0.5 * total_valid_num)\n",
    "\n",
    "valid_mask = list(range(valid_num))\n",
    "test_mask = list(range(valid_num, total_valid_num))\n",
    "\n",
    "valid_loader = DataLoader(Subset(valid_dataset, valid_mask), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(Subset(valid_dataset, test_mask), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "small_train_mask = random.sample(range(total_train_num), 1200)\n",
    "medium_train_mask = random.sample(range(total_train_num), 5000)\n",
    "small_valid_mask = random.sample(range(total_valid_num), 200)\n",
    "\n",
    "small_train_loader = DataLoader(Subset(train_dataset, list(small_train_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "small_valid_loader = DataLoader(Subset(valid_dataset, list(small_valid_mask)), batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=2)\n",
    "\n",
    "medium_loader = DataLoader(Subset(train_dataset, list(medium_train_mask)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'epochs': 20,\n",
    "    'vt_num_layers':3,\n",
    "    'resnet_pretrained': True,\n",
    "    'freeze_resnet': False,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.0005,\n",
    "    'vt_channels': 64,\n",
    "    'transformer_enc_layers': 2,\n",
    "    'transformer_n_heads': 1,\n",
    "    'transformer_fc_dims': 128,\n",
    "    'transformer_dropout': 0.5,\n",
    "    'tokens': 4,\n",
    "    'token_dims': 128,\n",
    "    'optimizer': 'adam',\n",
    "    'weight_decay': 8e-5,\n",
    "    'input_dim': input_dim,\n",
    "    'num_classes': num_classes,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, data_loader: Any, device: torch.device, comment: str = \"\"):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = len(data_loader.dataset)\n",
    "    correct_samples = 0\n",
    "    total_loss = 0\n",
    "    loss_history = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(data_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct_samples += pred.eq(target).sum()\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    wandb.log({'valid_loss': avg_loss})\n",
    "    \n",
    "    accuracy = 100.0 * correct_samples / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, data_loader, test_loader, device):\n",
    "    \n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "    \n",
    "    full_start = time.time()\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        print(f\"Starting Epoch {i}\")\n",
    "        \n",
    "        total_loss = 0\n",
    "        epoch_time = time.time()\n",
    "        num_batches = 0\n",
    "        for j, (data, label) in enumerate(data_loader):\n",
    "            \n",
    "            data, label = data.to(device), label.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = F.log_softmax(model(data), dim=1)\n",
    "            loss = F.nll_loss(output, label)\n",
    "            loss.backward()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            num_batches += 1\n",
    "            \n",
    "            wandb.log({'batch_loss': loss.item()})\n",
    "        print(f\"Finished Epoch {i}\")\n",
    "        \n",
    "        valid_accuracy = evaluate(model, test_loader, device)\n",
    "        train_accuracy = evaluate(model, data_loader, device)\n",
    "        \n",
    "        print(f\"Validation Accuracy: \", valid_accuracy)\n",
    "        print(f\"Training Accuracy: \", train_accuracy)\n",
    "        \n",
    "        wandb.log({\n",
    "            'loss': total_loss / num_batches,\n",
    "            'valid_accuracy': valid_accuracy,\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'epoch_time_minutes': (time.time() - epoch_time) / 60\n",
    "        })\n",
    "    wandb.log({'full_run_time_minutes': (time.time() - full_start) / 60})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparameters):\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    with wandb.init(project=project_name, config=hyperparameters):\n",
    "       \n",
    "        config = wandb.config\n",
    "        \n",
    "        model = VTResNet20(\n",
    "            vt_num_layers=config.vt_num_layers,\n",
    "            tokens=config.tokens,\n",
    "            token_channels=config.token_dims,\n",
    "            input_dim=config.input_dim,\n",
    "            vt_channels=config.vt_channels,\n",
    "            transformer_enc_layers=config.transformer_enc_layers,\n",
    "            transformer_heads=config.transformer_n_heads,\n",
    "            transformer_fc_dim=config.transformer_fc_dims,\n",
    "            transformer_dropout=config.transformer_dropout,\n",
    "            num_classes=config.num_classes,\n",
    "            resnet_pretrained=config.resnet_pretrained,\n",
    "            freeze_resnet=config.freeze_resnet,\n",
    "        )\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "           \n",
    "        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=cores)    \n",
    "        \n",
    "        train(model, optimizer, config.epochs, train_loader, valid_loader, device)\n",
    "\n",
    "        test_accuracy = evaluate(model, test_loader, device)\n",
    "        \n",
    "        sample = train_dataset[0][0].reshape(1, 3, config.input_dim, config.input_dim)\n",
    "        \n",
    "        wandb.log({'test_accuracy': test_accuracy})\n",
    "    \n",
    "    return model, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.20<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">generous-sky-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nazirnayal98/vt_resnet\" target=\"_blank\">https://wandb.ai/nazirnayal98/vt_resnet</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nazirnayal98/vt_resnet/runs/34va2c4r\" target=\"_blank\">https://wandb.ai/nazirnayal98/vt_resnet/runs/34va2c4r</a><br/>\n",
       "                Run data is saved locally in <code>/scratch/users/nnayal17/visual_transformer/visual-transformer/wandb/run-20210316_114601-34va2c4r</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:00<00:01, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.48it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(75.2800, device='cuda:0')\n",
      "Training Accuracy:  tensor(77.6000, device='cuda:0')\n",
      "Starting Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 3/40 [00:00<00:01, 26.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.28it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(81.0200, device='cuda:0')\n",
      "Training Accuracy:  tensor(83.4260, device='cuda:0')\n",
      "Starting Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 3/40 [00:00<00:01, 20.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.87it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(83.1400, device='cuda:0')\n",
      "Training Accuracy:  tensor(86.1200, device='cuda:0')\n",
      "Starting Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:02, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.41it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(83.9200, device='cuda:0')\n",
      "Training Accuracy:  tensor(87.4980, device='cuda:0')\n",
      "Starting Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:00<00:07,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 18.39it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(84.3200, device='cuda:0')\n",
      "Training Accuracy:  tensor(88.3500, device='cuda:0')\n",
      "Starting Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:01, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.27it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 41.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(83.7600, device='cuda:0')\n",
      "Training Accuracy:  tensor(87.3240, device='cuda:0')\n",
      "Starting Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:01, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.50it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(84.5800, device='cuda:0')\n",
      "Training Accuracy:  tensor(89.3300, device='cuda:0')\n",
      "Starting Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:01, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.58it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(85.7000, device='cuda:0')\n",
      "Training Accuracy:  tensor(90.4920, device='cuda:0')\n",
      "Starting Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:02, 18.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.53it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(85.6400, device='cuda:0')\n",
      "Training Accuracy:  tensor(90.9740, device='cuda:0')\n",
      "Starting Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [00:00<00:04,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 23.24it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.3000, device='cuda:0')\n",
      "Training Accuracy:  tensor(91.0240, device='cuda:0')\n",
      "Starting Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 3/40 [00:00<00:01, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.79it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(85.4200, device='cuda:0')\n",
      "Training Accuracy:  tensor(91.4660, device='cuda:0')\n",
      "Starting Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:02, 18.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 19.31it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(85.8200, device='cuda:0')\n",
      "Training Accuracy:  tensor(91.2540, device='cuda:0')\n",
      "Starting Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:02, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.29it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(85.2000, device='cuda:0')\n",
      "Training Accuracy:  tensor(91.2400, device='cuda:0')\n",
      "Starting Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:02, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 20.67it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.4400, device='cuda:0')\n",
      "Training Accuracy:  tensor(92.9420, device='cuda:0')\n",
      "Starting Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [00:00<00:07,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.03it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.3400, device='cuda:0')\n",
      "Training Accuracy:  tensor(92.7040, device='cuda:0')\n",
      "Starting Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 3/40 [00:00<00:01, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.08it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.4400, device='cuda:0')\n",
      "Training Accuracy:  tensor(92.4460, device='cuda:0')\n",
      "Starting Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:01, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 18.98it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.6400, device='cuda:0')\n",
      "Training Accuracy:  tensor(93.4540, device='cuda:0')\n",
      "Starting Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:02, 18.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.13it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 40.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(87., device='cuda:0')\n",
      "Training Accuracy:  tensor(93.7740, device='cuda:0')\n",
      "Starting Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [00:00<00:01, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.38it/s]\n",
      "100%|██████████| 391/391 [00:09<00:00, 39.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.5400, device='cuda:0')\n",
      "Training Accuracy:  tensor(93.4360, device='cuda:0')\n",
      "Starting Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [00:00<00:06,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 21.03it/s]\n",
      "100%|██████████| 391/391 [00:10<00:00, 39.01it/s]\n",
      "  8%|▊         | 3/40 [00:00<00:01, 20.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  tensor(86.5600, device='cuda:0')\n",
      "Training Accuracy:  tensor(93.6440, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 22.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 165339<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.02MB of 0.02MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/scratch/users/nnayal17/visual_transformer/visual-transformer/wandb/run-20210316_114601-34va2c4r/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/scratch/users/nnayal17/visual_transformer/visual-transformer/wandb/run-20210316_114601-34va2c4r/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>batch_loss</td><td>0.25741</td></tr><tr><td>_runtime</td><td>794</td></tr><tr><td>_timestamp</td><td>1615885155</td></tr><tr><td>_step</td><td>7882</td></tr><tr><td>valid_loss</td><td>0.45123</td></tr><tr><td>loss</td><td>0.20105</td></tr><tr><td>valid_accuracy</td><td>86.56</td></tr><tr><td>train_accuracy</td><td>93.644</td></tr><tr><td>epoch_time_minutes</td><td>0.66363</td></tr><tr><td>full_run_time_minutes</td><td>13.0903</td></tr><tr><td>test_accuracy</td><td>85.57999</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>batch_loss</td><td>█▄▄▄▃▂▃▃▂▃▃▃▂▂▂▂▂▃▂▂▂▁▂▂▂▁▂▂▁▂▂▂▁▂▂▂▁▂▁▂</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid_loss</td><td>█▇▆▅▅▄▅▃▅▃▅▃▄▃▄▂▄▂▄▂▄▂▄▂▅▂▄▁▄▁▄▁▄▁▄▁▄▁▄▄</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_accuracy</td><td>▁▄▆▆▆▆▇▇▇█▇▇▇███████</td></tr><tr><td>train_accuracy</td><td>▁▄▅▅▆▅▆▇▇▇▇▇▇██▇████</td></tr><tr><td>epoch_time_minutes</td><td>▄▅▅▄▇▃▆▁▃▃█▃▅▃▃█▄▅▂▇</td></tr><tr><td>full_run_time_minutes</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">generous-sky-12</strong>: <a href=\"https://wandb.ai/nazirnayal98/vt_resnet/runs/34va2c4r\" target=\"_blank\">https://wandb.ai/nazirnayal98/vt_resnet/runs/34va2c4r</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, test_accuracy = train_model(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84.1800, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 64, 16, 16]' is invalid for input of size 1605632",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e6b200a7f562>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/nazir_env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/nnayal17/visual_transformer/visual-transformer/models/vt_resnet20.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvt_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvt_layer_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvt_layer_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 64, 16, 16]' is invalid for input of size 1605632"
     ]
    }
   ],
   "source": [
    "# summary(model.to(torch.device('cuda:0')), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nazir_env",
   "language": "python",
   "name": "nazir_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
